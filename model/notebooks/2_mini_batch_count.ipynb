{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import argparse\n",
    "parent_path = pathlib.Path(os.getcwd()).parent.absolute()\n",
    "sys.path.append(str(parent_path))\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import MovieLens\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "from torch_geometric.loader import NeighborLoader, LinkNeighborLoader\n",
    "\n",
    "from utils.Neo4jMovieLensMetaData import Neo4jMovieLensMetaData\n",
    "# from utils.gnn_simple import Model\n",
    "from utils.train_test import train_test\n",
    "from utils.visualize import plot_loss, plot_train, plot_val, plot_test, plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the corresponsing csv, store the dataset to the DB, preprocess it, and get it as a pytorch graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies have features...\n",
      "Encoding title...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 565/565 [00:15<00:00, 36.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([18062, 64])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "path = osp.join(osp.dirname(osp.abspath('')), '../../data/MovieLensNeo4j')\n",
    "dataset = Neo4jMovieLensMetaData(\n",
    "    path,\n",
    "    model_name='all-MiniLM-L6-v2',\n",
    "    database_url=\"bolt://localhost:7687\",\n",
    "    database_username=\"neo4j\",\n",
    "    database_password=\"admin\",\n",
    "    force_pre_process=True,\n",
    "    force_db_restore=False,\n",
    "    text_features=[\"title\"],\n",
    "    list_features=[],\n",
    "    fastRP_features=[],\n",
    "    numeric_features=[],\n",
    ")\n",
    "data = dataset[0].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add user node features for message passing:\n",
    "data['user'].x = torch.eye(data['user'].num_nodes, device=device)\n",
    "del data['user'].num_nodes\n",
    "\n",
    "# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\n",
    "data = T.ToUndirected()(data)\n",
    "del data['movie', 'rev_rates', 'user'].edge_label  # Remove \"reverse\" label.\n",
    "\n",
    "# Perform a link-level split into training, validation, and test edges:\n",
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.7,\n",
    "    num_test=0.1,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('user', 'rates', 'movie')],\n",
    "    rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
    ")(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4,  ..., 3, 4, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['user', 'movie'].edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = LinkNeighborLoader(\n",
    "#     data=train_data,\n",
    "#     # Sample ALL neighbors for each node and each edge type for 2 iterations:\n",
    "#     num_neighbors=[-1],\n",
    "#     # Use a batch size of 128 for sampling training nodes of type \"paper\":\n",
    "#     batch_size=1024,\n",
    "#     edge_label_index = ((\"user\", \"movie\"), None),\n",
    "#     edge_label = train_data['user', 'movie'].edge_label,\n",
    "# )\n",
    "# train_batch = next(iter(train_loader))\n",
    "\n",
    "\n",
    "edge_label_index = train_data[\"user\", \"rates\", \"movie\"].edge_label_index\n",
    "edge_label = train_data[\"user\", \"rates\", \"movie\"].edge_label\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[15, 5],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "train_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader = LinkNeighborLoader(\n",
    "#     data=test_data,\n",
    "#     # Sample ALL neighbors for each node and each edge type for 2 iterations:\n",
    "#     num_neighbors=[-1],\n",
    "#     # Use a batch size of 128 for sampling training nodes of type \"paper\":\n",
    "#     batch_size=1024,\n",
    "#     edge_label_index = ((\"user\", \"movie\"), None),\n",
    "#     edge_label = test_data['user', 'movie'].edge_label,\n",
    "# )\n",
    "# test_batch = next(iter(test_loader))\n",
    "\n",
    "test_loader = LinkNeighborLoader(\n",
    "    data=test_data,\n",
    "    num_neighbors=[15],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define and train-test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, LazyLinear, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, GATv2Conv, GCNConv, TransformerConv, GraphConv, GINConv, GINEConv, to_hetero, HeteroLinear, HeteroConv\n",
    "from torch_geometric.nn.models import GIN, GraphSAGE\n",
    "from torch_geometric.nn.aggr import MultiAggregation\n",
    "from typing import Union\n",
    "from torch_geometric.typing import Adj, OptPairTensor, Size\n",
    "\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        global z_dict_test_lala, edge_label_index_test_lala\n",
    "        row, col = edge_label_index\n",
    "        z_dict_test_lala = z_dict\n",
    "        edge_label_index_test_lala = edge_label_index\n",
    "        movie = z_dict['movie'][col]\n",
    "        user = z_dict['user'][row]\n",
    "        z = torch.cat([user, movie], dim=-1)\n",
    "\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(hidden_channels=16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.encoder(train_batch.x_dict, train_batch.edge_index_dict)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.012)\n",
    "\n",
    "weight = None\n",
    "# weight = torch.bincount(train_data['user', 'movie'].edge_label)\n",
    "# weight = weight.max() / weight\n",
    "\n",
    "def weighted_mse_loss(pred, target, weight=None):\n",
    "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
    "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch, log=False):\n",
    "    pred = model(batch.x_dict, batch.edge_index_dict, batch['user', 'movie'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=5)\n",
    "    target = batch['user', 'movie'].edge_label.float()\n",
    "    loss = weighted_mse_loss(pred, target, weight)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(batch, log=False):\n",
    "    pred = model(batch.x_dict, batch.edge_index_dict, batch['user', 'movie'].edge_label_index)\n",
    "    pred = pred.clamp(min=0, max=5)\n",
    "    target = batch['user', 'movie'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    return float(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = batch_index = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device, 'edge_index')\n",
    "        loss = train(batch)\n",
    "        # print(f'Batch {batch_index:03d}, Train Loss: {loss:.4f}')\n",
    "        total_loss += loss\n",
    "        # train_rmse = test(batch)\n",
    "        # test_rmse = test()\n",
    "        # losses.append((loss, train_rmse, test_rmse))\n",
    "        # losses.append((loss, train_rmse, test_rmse))\n",
    "        # print(f'Batch {batch_index:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, Test: {test_rmse:.4f}')\n",
    "        batch_index += 1\n",
    "    return total_loss / batch_index if batch_index else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch():\n",
    "    model.eval()\n",
    "    total_loss = batch_index = 0\n",
    "    for batch in tqdm(test_loader):\n",
    "        batch = batch.to(device, 'edge_index')\n",
    "        loss = test(batch)\n",
    "        # print(f'Batch {batch_index:03d}, Test Loss: {loss:.4f}')\n",
    "        total_loss += loss\n",
    "        # train_rmse = test(batch)\n",
    "        # test_rmse = test()\n",
    "        # losses.append((loss, train_rmse, test_rmse))\n",
    "        # losses.append((loss, train_rmse, test_rmse))\n",
    "        # print(f'Batch {batch_index:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, Test: {test_rmse:.4f}')\n",
    "        batch_index += 1\n",
    "    return total_loss / batch_index if batch_index else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4158/4158 [23:16<00:00,  2.98it/s]\n",
      "100%|██████████| 4158/4158 [06:45<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 001, Loss: 7.1764, Test: 2.6784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4158/4158 [23:03<00:00,  3.01it/s]\n",
      "100%|██████████| 4158/4158 [06:39<00:00, 10.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 002, Loss: 7.1766, Test: 2.6784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "losses = []\n",
    "epoch_index = 1\n",
    "for epoch in range(1, epochs+1):\n",
    "        train_loss = train_epoch()\n",
    "        test_loss = test_epoch()\n",
    "                # train_rmse = test(batch)\n",
    "                # test_rmse = test()\n",
    "                # losses.append((loss, train_rmse, test_rmse))\n",
    "                # losses.append((loss, train_rmse, test_rmse))\n",
    "        print(f'Batch {epoch_index:03d}, Loss: {train_loss:.4f}, Test: {test_loss:.4f}')\n",
    "        epoch_index += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('environ': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acbc58aadc5672afc04cc91f2a1726d8eb7b999e15e50d024070fdc74729208f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
