{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ioannisathanasiou/diploma/environ/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, LazyLinear, Sequential, BatchNorm1d, ReLU\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import MovieLens\n",
    "from torch_geometric.nn import SAGEConv, to_hetero, LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import sys\n",
    "parent_path = pathlib.Path(os.getcwd()).parent.absolute()\n",
    "sys.path.append(str(parent_path))\n",
    "from utils.Neo4jMovieLensMetaData import Neo4jMovieLensMetaData\n",
    "from utils.gnn_simple import Model\n",
    "from utils.visualize import plot_loss, plot_test\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = osp.join(osp.dirname(osp.abspath('')), '../../data/MovieLensNeo4jMetaData')\n",
    "# dataset = Neo4jMovieLensMetaData(\n",
    "#     path,\n",
    "#     model_name='all-MiniLM-L6-v2',\n",
    "#     database_url=\"bolt://localhost:7687\",\n",
    "#     database_username=\"neo4j\",\n",
    "#     database_password=\"admin\",\n",
    "#     force_pre_process=True,\n",
    "#     force_db_restore=False,\n",
    "#     text_features=[\"title\", \"original_title\"],\n",
    "#     list_features=[],\n",
    "#     fastRP_features=[],\n",
    "#     numeric_features=[],\n",
    "# )\n",
    "\n",
    "path = osp.join(osp.dirname(osp.abspath('')), '../../data/MovieLens')\n",
    "dataset = MovieLens(path, model_name='all-MiniLM-L6-v2')\n",
    "data = dataset[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0].to(device)\n",
    "# Add user node features for message passing:\n",
    "data['user'].x = torch.eye(data['user'].num_nodes, device=device)\n",
    "del data['user'].num_nodes\n",
    "# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\n",
    "data = T.ToUndirected()(data)\n",
    "del data['movie', 'rev_rates', 'user'].edge_label  # Remove \"reverse\" label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "    num_val=0.05,\n",
    "    num_test=0.15,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    edge_types=[('user', 'rates', 'movie')],\n",
    "    rev_edge_types=[('movie', 'rev_rates', 'user')],\n",
    ")(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovie\u001b[0m={ x=[9742, 404] },\n",
       "  \u001b[1muser\u001b[0m={ x=[610, 610] },\n",
       "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
       "    edge_index=[2, 100836],\n",
       "    edge_label=[100836]\n",
       "  },\n",
       "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 100836] }\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, LazyLinear, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, GATv2Conv, GCNConv, TransformerConv, GraphConv, GINConv, GINEConv, to_hetero, LGConv\n",
    "from torch_geometric.nn.models import GIN, GraphSAGE\n",
    "from torch_geometric.nn.aggr import MultiAggregation\n",
    "from typing import Union\n",
    "from torch_geometric.typing import Adj, OptPairTensor, Size\n",
    "\n",
    "layers = {\n",
    "    \"SAGE\": SAGEConv,\n",
    "    \"GAT\": GATv2Conv,\n",
    "    \"GCN\": GCNConv,\n",
    "    \"Transformer\": TransformerConv,\n",
    "    \"GraphConv\": GraphConv,\n",
    "    \"GIN\": GINConv,\n",
    "    \"GINE\": GINEConv,\n",
    "    \"LightGCN\": LGConv,\n",
    "}\n",
    "\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, layer_name=\"SAGE\", num_layers=4, in_channels=-1, hidden_channels=32, out_channels=32, dropout=0.1, skip_connections=True, encoder_aggr=[]):\n",
    "        assert num_layers >= 2\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.dropout = dropout\n",
    "        self.skip_connections = skip_connections\n",
    "        self.layer = layers.get(layer_name) or SAGEConv\n",
    "        self.layer_name = layer_name\n",
    "        print(self.layer_name)\n",
    "        \n",
    "        self.aggr = None\n",
    "        if encoder_aggr:\n",
    "            if isinstance(encoder_aggr, str):\n",
    "                self.aggr = encoder_aggr\n",
    "            if len(encoder_aggr) == 1:\n",
    "                self.aggr = encoder_aggr[0]\n",
    "            if len(encoder_aggr) > 1:\n",
    "                self.aggr = MultiAggregation(encoder_aggr)\n",
    "        \n",
    "        print(\"Aggregation:\", self.aggr)\n",
    "\n",
    "        if self.layer_name != \"LightGCN\":\n",
    "            first_layer_args = {\n",
    "                \"in_channels\": self.in_channels,\n",
    "                \"out_channels\": self.hidden_channels,\n",
    "                # \"aggr\": self.aggr,\n",
    "                # **encoder_extra_config,\n",
    "            }\n",
    "            hidden_layer_args = {\n",
    "                \"in_channels\": self.hidden_channels,\n",
    "                \"out_channels\": self.hidden_channels,\n",
    "                # \"aggr\": self.aggr,\n",
    "                # **encoder_extra_config,\n",
    "            }\n",
    "            last_layer_args = {\n",
    "                \"in_channels\": self.hidden_channels,\n",
    "                \"out_channels\": self.out_channels,\n",
    "                # \"aggr\": self.aggr,\n",
    "                # **encoder_extra_config,\n",
    "            }\n",
    "            if self.aggr:\n",
    "                first_layer_args[\"aggr\"] = self.aggr\n",
    "                hidden_layer_args[\"aggr\"] = self.aggr\n",
    "                last_layer_args[\"aggr\"] = self.aggr\n",
    "        else:\n",
    "            first_layer_args = {}\n",
    "            hidden_layer_args = {}\n",
    "            last_layer_args = {}\n",
    "\n",
    "        if layer_name in [\"GCN\", \"GAT\"]:\n",
    "            first_layer_args[\"add_self_loops\"] = False\n",
    "            hidden_layer_args[\"add_self_loops\"] = False\n",
    "            last_layer_args[\"add_self_loops\"] = False\n",
    "        \n",
    "        if self.layer_name == \"GIN\" or self.layer_name == \"GINE\":\n",
    "            del hidden_layer_args[\"in_channels\"]\n",
    "            del hidden_layer_args[\"out_channels\"]\n",
    "            # hidden_layer_args[\"train_eps\"] = True\n",
    "            hidden_layer_args[\"nn\"] = Sequential(\n",
    "                Linear(hidden_channels, hidden_channels),\n",
    "                BatchNorm1d(hidden_channels),\n",
    "                ReLU(),\n",
    "                Linear(hidden_channels, hidden_channels),\n",
    "                BatchNorm1d(hidden_channels),\n",
    "                ReLU(),\n",
    "                Linear(hidden_channels, hidden_channels),\n",
    "                BatchNorm1d(hidden_channels),\n",
    "                ReLU(),\n",
    "                Linear(hidden_channels, hidden_channels),\n",
    "                ReLU()\n",
    "            )\n",
    "\n",
    "            del last_layer_args[\"in_channels\"]\n",
    "            del last_layer_args[\"out_channels\"]\n",
    "            # last_layer_args[\"train_eps\"] = True\n",
    "            last_layer_args[\"nn\"] = Sequential(\n",
    "                Linear(hidden_channels, hidden_channels),\n",
    "                BatchNorm1d(hidden_channels),\n",
    "                ReLU(),\n",
    "                Linear(hidden_channels, hidden_channels),\n",
    "                BatchNorm1d(hidden_channels),\n",
    "                ReLU(),\n",
    "                Linear(hidden_channels, hidden_channels),\n",
    "                BatchNorm1d(hidden_channels),\n",
    "                ReLU(),\n",
    "                Linear(hidden_channels, out_channels),\n",
    "                ReLU()\n",
    "            )\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        if self.layer_name == \"GIN\":\n",
    "            self.convs.append(SAGEConv(**first_layer_args))\n",
    "        else:\n",
    "            self.convs.append(self.layer(**first_layer_args))\n",
    "        for _ in range(self.num_layers-2):\n",
    "            self.convs.append(self.layer(**hidden_layer_args))\n",
    "        self.convs.append(self.layer(**last_layer_args))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        prev_x = None\n",
    "        for i in range(len(self.convs)-1):\n",
    "            prev_x = x\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            # x = self.convs[i](x, edge_index, conv_index=i)\n",
    "            if i > 0 and self.skip_connections:\n",
    "                x = x + prev_x\n",
    "            x = x.relu()\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_layers):\n",
    "        assert num_layers >= 2\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "\n",
    "        self.layers.append(LazyLinear(self.hidden_channels))\n",
    "        for _ in range(self.num_layers-2):\n",
    "            self.layers.append(\n",
    "                Linear(self.hidden_channels, self.hidden_channels))\n",
    "        self.layers.append(Linear(self.hidden_channels, 1))\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        user_embeddings = z_dict['user'][row]\n",
    "        movie_embeddings = z_dict['movie'][col]\n",
    "        z = torch.cat([user_embeddings, movie_embeddings], dim=-1)\n",
    "        for i in range(self.num_layers-1):\n",
    "            z = self.layers[i](z).relu()\n",
    "        z = self.layers[self.num_layers-1](z)\n",
    "        return z.view(-1)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, data, in_channels=-1, hidden_channels=32, out_channels=32, encoder_num_layers=5, decoder_num_layers=4, layer_name=\"SAGE\", encoder_dropout=0.1, encoder_skip_connections=True, encoder_aggr=[]):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(\n",
    "            in_channels=in_channels,\n",
    "            hidden_channels=hidden_channels,\n",
    "            out_channels=out_channels,\n",
    "            layer_name=layer_name,\n",
    "            num_layers=encoder_num_layers,\n",
    "            dropout=encoder_dropout,\n",
    "            skip_connections=encoder_skip_connections,\n",
    "            encoder_aggr=encoder_aggr,\n",
    "        )\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(\n",
    "            hidden_channels,\n",
    "            num_layers=decoder_num_layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAGE\n",
      "Aggregation: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ioannisathanasiou/diploma/environ/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# model = Model(data, layer_name=\"SAGE\", hidden_channels=32, encoder_num_layers=4, decoder_num_layers=4, encoder_skip_connections=True, encoder_aggr=[\"mean\"])\n",
    "model = Model(\n",
    "    data,\n",
    "    layer_name=\"SAGE\",\n",
    "    encoder_num_layers=4,\n",
    "    encoder_dropout=0.1,\n",
    "    encoder_skip_connections=True,\n",
    "    decoder_num_layers=12,\n",
    "    hidden_channels=16,\n",
    "    out_channels=16,\n",
    ")\n",
    "# model = LightGCN(num_nodes=data.num_nodes, embedding_dim=32, num_layers=3)\n",
    "lr = 0.016\n",
    "with torch.no_grad():\n",
    "    model.encoder(train_data.x_dict, train_data.edge_index_dict)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# weight = torch.bincount(train_data['user', 'movie'].edge_label)\n",
    "# weight = weight.max() / weight\n",
    "weight = None\n",
    "def weighted_rmse_loss(pred, target, weight=None):\n",
    "    # weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
    "    weight = 1.\n",
    "    # return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()\n",
    "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 12.7246, Train: 3.5017, Val: 3.5225, Test: 3.4977\n",
      "Epoch: 002, Loss: 12.2619, Train: 3.4433, Val: 3.4640, Test: 3.4393\n",
      "Epoch: 003, Loss: 11.8560, Train: 3.3886, Val: 3.4093, Test: 3.3846\n",
      "Epoch: 004, Loss: 11.4825, Train: 3.3275, Val: 3.3482, Test: 3.3236\n",
      "Epoch: 005, Loss: 11.0723, Train: 3.2339, Val: 3.2547, Test: 3.2304\n",
      "Epoch: 006, Loss: 10.4574, Train: 3.0209, Val: 3.0446, Test: 3.0195\n",
      "Epoch: 007, Loss: 9.1312, Train: 2.3741, Val: 2.3949, Test: 2.3709\n",
      "Epoch: 008, Loss: 5.6196, Train: 1.2489, Val: 1.2196, Test: 1.2363\n",
      "Epoch: 009, Loss: 1.5331, Train: 1.4953, Val: 1.4405, Test: 1.4859\n",
      "Epoch: 010, Loss: 2.2618, Train: 1.4276, Val: 1.4466, Test: 1.4238\n",
      "Epoch: 011, Loss: 1.9990, Train: 1.6949, Val: 1.7323, Test: 1.7012\n",
      "Epoch: 012, Loss: 2.8754, Train: 1.5543, Val: 1.5937, Test: 1.5779\n",
      "Epoch: 013, Loss: 2.4812, Train: 1.1740, Val: 1.2023, Test: 1.1885\n",
      "Epoch: 014, Loss: 1.3930, Train: 1.3363, Val: 1.2914, Test: 1.3145\n",
      "Epoch: 015, Loss: 1.8516, Train: 1.3053, Val: 1.3054, Test: 1.3085\n",
      "Epoch: 016, Loss: 1.7828, Train: 1.0908, Val: 1.0916, Test: 1.0966\n",
      "Epoch: 017, Loss: 1.1831, Train: 1.2283, Val: 1.2312, Test: 1.2324\n",
      "Epoch: 018, Loss: 1.4834, Train: 1.2833, Val: 1.3010, Test: 1.2885\n",
      "Epoch: 019, Loss: 1.6294, Train: 1.2206, Val: 1.2379, Test: 1.2277\n",
      "Epoch: 020, Loss: 1.4955, Train: 1.1058, Val: 1.1113, Test: 1.1132\n",
      "Epoch: 021, Loss: 1.2296, Train: 1.1160, Val: 1.0917, Test: 1.1041\n",
      "Epoch: 022, Loss: 1.2250, Train: 1.2259, Val: 1.1878, Test: 1.1971\n",
      "Epoch: 023, Loss: 1.4734, Train: 1.1520, Val: 1.1368, Test: 1.1493\n",
      "Epoch: 024, Loss: 1.3198, Train: 1.0856, Val: 1.0779, Test: 1.0768\n",
      "Epoch: 025, Loss: 1.1701, Train: 1.1123, Val: 1.1158, Test: 1.1110\n",
      "Epoch: 026, Loss: 1.2363, Train: 1.1447, Val: 1.1465, Test: 1.1433\n",
      "Epoch: 027, Loss: 1.3020, Train: 1.1421, Val: 1.1429, Test: 1.1389\n",
      "Epoch: 028, Loss: 1.2866, Train: 1.1099, Val: 1.1132, Test: 1.1055\n",
      "Epoch: 029, Loss: 1.2284, Train: 1.0832, Val: 1.0862, Test: 1.0793\n",
      "Epoch: 030, Loss: 1.1712, Train: 1.0936, Val: 1.0815, Test: 1.0892\n",
      "Epoch: 031, Loss: 1.1898, Train: 1.1153, Val: 1.0966, Test: 1.1097\n",
      "Epoch: 032, Loss: 1.2298, Train: 1.1020, Val: 1.0926, Test: 1.1008\n",
      "Epoch: 033, Loss: 1.2342, Train: 1.0901, Val: 1.0817, Test: 1.0824\n",
      "Epoch: 034, Loss: 1.1747, Train: 1.0800, Val: 1.0799, Test: 1.0789\n",
      "Epoch: 035, Loss: 1.1654, Train: 1.0891, Val: 1.0912, Test: 1.0871\n",
      "Epoch: 036, Loss: 1.1817, Train: 1.0971, Val: 1.0996, Test: 1.0992\n",
      "Epoch: 037, Loss: 1.2070, Train: 1.0975, Val: 1.0965, Test: 1.0960\n",
      "Epoch: 038, Loss: 1.1980, Train: 1.0852, Val: 1.0853, Test: 1.0826\n",
      "Epoch: 039, Loss: 1.1784, Train: 1.0771, Val: 1.0761, Test: 1.0765\n",
      "Epoch: 040, Loss: 1.1637, Train: 1.0802, Val: 1.0744, Test: 1.0771\n",
      "Epoch: 041, Loss: 1.1705, Train: 1.0877, Val: 1.0787, Test: 1.0863\n",
      "Epoch: 042, Loss: 1.1769, Train: 1.0874, Val: 1.0773, Test: 1.0845\n",
      "Epoch: 043, Loss: 1.1820, Train: 1.0798, Val: 1.0749, Test: 1.0764\n",
      "Epoch: 044, Loss: 1.1658, Train: 1.0733, Val: 1.0701, Test: 1.0752\n",
      "Epoch: 045, Loss: 1.1575, Train: 1.0806, Val: 1.0779, Test: 1.0784\n",
      "Epoch: 046, Loss: 1.1648, Train: 1.0824, Val: 1.0845, Test: 1.0808\n",
      "Epoch: 047, Loss: 1.1694, Train: 1.0813, Val: 1.0814, Test: 1.0819\n",
      "Epoch: 048, Loss: 1.1693, Train: 1.0786, Val: 1.0781, Test: 1.0759\n",
      "Epoch: 049, Loss: 1.1600, Train: 1.0749, Val: 1.0710, Test: 1.0748\n",
      "Epoch: 050, Loss: 1.1507, Train: 1.0759, Val: 1.0700, Test: 1.0754\n",
      "Epoch: 051, Loss: 1.1543, Train: 1.0770, Val: 1.0709, Test: 1.0749\n",
      "Epoch: 052, Loss: 1.1648, Train: 1.0756, Val: 1.0702, Test: 1.0748\n",
      "Epoch: 053, Loss: 1.1597, Train: 1.0731, Val: 1.0694, Test: 1.0749\n",
      "Epoch: 054, Loss: 1.1522, Train: 1.0722, Val: 1.0712, Test: 1.0716\n",
      "Epoch: 055, Loss: 1.1462, Train: 1.0730, Val: 1.0690, Test: 1.0714\n",
      "Epoch: 056, Loss: 1.1514, Train: 1.0752, Val: 1.0719, Test: 1.0732\n",
      "Epoch: 057, Loss: 1.1500, Train: 1.0717, Val: 1.0715, Test: 1.0716\n",
      "Epoch: 058, Loss: 1.1502, Train: 1.0709, Val: 1.0701, Test: 1.0709\n",
      "Epoch: 059, Loss: 1.1482, Train: 1.0679, Val: 1.0663, Test: 1.0706\n",
      "Epoch: 060, Loss: 1.1411, Train: 1.0699, Val: 1.0670, Test: 1.0698\n",
      "Epoch: 061, Loss: 1.1445, Train: 1.0699, Val: 1.0654, Test: 1.0692\n",
      "Epoch: 062, Loss: 1.1471, Train: 1.0680, Val: 1.0629, Test: 1.0672\n",
      "Epoch: 063, Loss: 1.1401, Train: 1.0660, Val: 1.0628, Test: 1.0668\n",
      "Epoch: 064, Loss: 1.1340, Train: 1.0673, Val: 1.0621, Test: 1.0642\n",
      "Epoch: 065, Loss: 1.1365, Train: 1.0694, Val: 1.0636, Test: 1.0662\n",
      "Epoch: 066, Loss: 1.1367, Train: 1.0656, Val: 1.0660, Test: 1.0649\n",
      "Epoch: 067, Loss: 1.1322, Train: 1.0626, Val: 1.0628, Test: 1.0633\n",
      "Epoch: 068, Loss: 1.1310, Train: 1.0618, Val: 1.0609, Test: 1.0625\n",
      "Epoch: 069, Loss: 1.1278, Train: 1.0612, Val: 1.0595, Test: 1.0627\n",
      "Epoch: 070, Loss: 1.1238, Train: 1.0636, Val: 1.0595, Test: 1.0625\n",
      "Epoch: 071, Loss: 1.1197, Train: 1.0594, Val: 1.0552, Test: 1.0612\n",
      "Epoch: 072, Loss: 1.1259, Train: 1.0580, Val: 1.0550, Test: 1.0597\n",
      "Epoch: 073, Loss: 1.1170, Train: 1.0571, Val: 1.0565, Test: 1.0589\n",
      "Epoch: 074, Loss: 1.1167, Train: 1.0582, Val: 1.0568, Test: 1.0612\n",
      "Epoch: 075, Loss: 1.1203, Train: 1.0577, Val: 1.0570, Test: 1.0594\n",
      "Epoch: 076, Loss: 1.1162, Train: 1.0544, Val: 1.0555, Test: 1.0573\n",
      "Epoch: 077, Loss: 1.1115, Train: 1.0526, Val: 1.0550, Test: 1.0538\n",
      "Epoch: 078, Loss: 1.1069, Train: 1.0510, Val: 1.0499, Test: 1.0547\n",
      "Epoch: 079, Loss: 1.1037, Train: 1.0491, Val: 1.0512, Test: 1.0514\n",
      "Epoch: 080, Loss: 1.1043, Train: 1.0462, Val: 1.0456, Test: 1.0530\n",
      "Epoch: 081, Loss: 1.1033, Train: 1.0470, Val: 1.0451, Test: 1.0492\n",
      "Epoch: 082, Loss: 1.0920, Train: 1.0440, Val: 1.0443, Test: 1.0480\n",
      "Epoch: 083, Loss: 1.0927, Train: 1.0436, Val: 1.0442, Test: 1.0464\n",
      "Epoch: 084, Loss: 1.0880, Train: 1.0449, Val: 1.0446, Test: 1.0449\n",
      "Epoch: 085, Loss: 1.0866, Train: 1.0388, Val: 1.0397, Test: 1.0440\n",
      "Epoch: 086, Loss: 1.0807, Train: 1.0388, Val: 1.0340, Test: 1.0422\n",
      "Epoch: 087, Loss: 1.0759, Train: 1.0363, Val: 1.0352, Test: 1.0390\n",
      "Epoch: 088, Loss: 1.0697, Train: 1.0330, Val: 1.0333, Test: 1.0383\n",
      "Epoch: 089, Loss: 1.0768, Train: 1.0295, Val: 1.0350, Test: 1.0363\n",
      "Epoch: 090, Loss: 1.0606, Train: 1.0284, Val: 1.0308, Test: 1.0341\n",
      "Epoch: 091, Loss: 1.0598, Train: 1.0289, Val: 1.0298, Test: 1.0347\n",
      "Epoch: 092, Loss: 1.0577, Train: 1.0258, Val: 1.0250, Test: 1.0301\n",
      "Epoch: 093, Loss: 1.0486, Train: 1.0224, Val: 1.0206, Test: 1.0277\n",
      "Epoch: 094, Loss: 1.0510, Train: 1.0201, Val: 1.0223, Test: 1.0259\n",
      "Epoch: 095, Loss: 1.0373, Train: 1.0176, Val: 1.0170, Test: 1.0240\n",
      "Epoch: 096, Loss: 1.0358, Train: 1.0139, Val: 1.0187, Test: 1.0232\n",
      "Epoch: 097, Loss: 1.0348, Train: 1.0129, Val: 1.0137, Test: 1.0234\n",
      "Epoch: 098, Loss: 1.0281, Train: 1.0093, Val: 1.0106, Test: 1.0186\n",
      "Epoch: 099, Loss: 1.0165, Train: 1.0080, Val: 1.0113, Test: 1.0169\n",
      "Epoch: 100, Loss: 1.0145, Train: 1.0046, Val: 1.0069, Test: 1.0122\n"
     ]
    }
   ],
   "source": [
    "def train(log=False):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
    "            train_data['user', 'movie'].edge_label_index)\n",
    "    # print(pred[:10])\n",
    "    target = train_data['user', 'movie'].edge_label\n",
    "\n",
    "    loss = weighted_rmse_loss(pred, target, weight)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data, log=False):\n",
    "    model.eval()\n",
    "    pred = model(data.x_dict, data.edge_index_dict,\n",
    "            data['user', 'movie'].edge_label_index)\n",
    "    # print(pred[:10])\n",
    "    # pred = pred.clamp(min=0, max=5)\n",
    "    target = data['user', 'movie'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    # mae = F.l1_loss(pred, target)\n",
    "    return float(rmse)\n",
    "\n",
    "# early_stopper = EarlyStopper(patience=100, min_delta=0.1)\n",
    "epochs = 100\n",
    "losses = []\n",
    "for epoch in range(1, epochs+1):\n",
    "    loss = train(log=not(epoch%20))\n",
    "    train_rmse = test(train_data)\n",
    "    val_rmse = test(val_data)\n",
    "    test_rmse = test(test_data, log=not(epoch%20))\n",
    "    losses.append((loss, train_rmse, val_rmse, test_rmse))\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
    "        f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')\n",
    "    # if epoch > 50 and early_stopper.early_stop(val_rmse):\n",
    "    #     print(\"Early stopping...\")\n",
    "    #     break\n",
    "\n",
    "last_losses = losses[-1]\n",
    "losses = losses + [last_losses] * (epochs - len(losses))\n",
    "losses_ = {\"SAGE\": losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(losses_, ylim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 22 artists>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model(test_data.x_dict, test_data.edge_index_dict, test_data[\"user\", \"movie\"].edge_label_index)\n",
    "ratings = pred.detach().numpy()\n",
    "# dummy way but never mind\n",
    "def get_group(i):\n",
    "    if i<0.25:\n",
    "        return 0\n",
    "    elif i<0.75:\n",
    "        return 0.5\n",
    "    elif i < 1.25:\n",
    "        return 1\n",
    "    elif i < 1.75:\n",
    "        return 1.5\n",
    "    elif i < 2.25:\n",
    "        return 2\n",
    "    elif i < 2.75:\n",
    "        return 2.5\n",
    "    elif i < 3.25:\n",
    "        return 3\n",
    "    elif i < 3.75:\n",
    "        return 3.5\n",
    "    elif i < 4.5:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "counters = defaultdict(int)\n",
    "for rating in ratings:\n",
    "    counters[round(rating, 1)] += 1\n",
    "plt.bar(counters.keys(), counters.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer, ModelConfig, \\\n",
    "    HeteroExplanation, \\\n",
    "    CaptumExplainer, DummyExplainer, PGExplainer, AttentionExplainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=DummyExplainer(),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='edge',\n",
    "        return_type='raw',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_label_index = train_data['user', 'movie'].edge_label_index[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 386, 4493])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 386,   11,  134,  ...,  559,  562,   38],\n",
       "        [4493,  644, 2437,  ...,  520, 8924, 1187]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[(\"user\", \"rates\", \"movie\")].edge_label_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer(\n",
    "    # x={\n",
    "    #     \"movie\": train_data[\"movie\"],\n",
    "    #     \"user\": train_data[\"user\"]\n",
    "    # },\n",
    "    # edge_index=train_data[(\"user\", \"rates\", \"movie\")].edge_index,\n",
    "    \n",
    "    edge_index=train_data.edge_index_dict,\n",
    "    \n",
    "    # edge_index=train_data[(\"user\", \"rates\", \"movie\")].edge_index,\n",
    "    \n",
    "    x=train_data.x_dict,\n",
    "    \n",
    "    # edge_index_dict=train_data.edge_index_dict,\n",
    "    \n",
    "    # edge_label_index=train_data['user', 'movie'].edge_label_index,\n",
    "    edge_label_index=edge_label_index,\n",
    "    \n",
    "    # edge_index=train_data.edge_index_dict[('user', 'rates', 'movie')],\n",
    "    # edge_label_index=train_data,\n",
    "    \n",
    "    target=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroExplanation(\n",
       "  prediction=[1],\n",
       "  target=[1],\n",
       "  edge_label_index=[2],\n",
       "  \u001b[1mmovie\u001b[0m={\n",
       "    node_mask=[9742, 404],\n",
       "    x=[9742, 404]\n",
       "  },\n",
       "  \u001b[1muser\u001b[0m={\n",
       "    node_mask=[610, 610],\n",
       "    x=[610, 610]\n",
       "  },\n",
       "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
       "    edge_mask=[80670],\n",
       "    edge_index=[2, 80670]\n",
       "  },\n",
       "  \u001b[1m(movie, rev_rates, user)\u001b[0m={\n",
       "    edge_mask=[80670],\n",
       "    edge_index=[2, 80670]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation.get_explanation_subgraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovie\u001b[0m={ x=[9742, 404] },\n",
       "  \u001b[1muser\u001b[0m={ x=[610, 610] },\n",
       "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
       "    edge_index=[2, 80670],\n",
       "    edge_label=[80670],\n",
       "    edge_label_index=[2, 80670]\n",
       "  },\n",
       "  \u001b[1m(movie, rev_rates, user)\u001b[0m={ edge_index=[2, 80670] }\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroExplanation(\n",
       "  prediction=[1],\n",
       "  target=[1],\n",
       "  edge_label_index=[2],\n",
       "  \u001b[1mmovie\u001b[0m={\n",
       "    node_mask=[9742, 404],\n",
       "    x=[9742, 404]\n",
       "  },\n",
       "  \u001b[1muser\u001b[0m={\n",
       "    node_mask=[610, 610],\n",
       "    x=[610, 610]\n",
       "  },\n",
       "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
       "    edge_mask=[80670],\n",
       "    edge_index=[2, 80670]\n",
       "  },\n",
       "  \u001b[1m(movie, rev_rates, user)\u001b[0m={\n",
       "    edge_mask=[80670],\n",
       "    edge_index=[2, 80670]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation.get_explanation_subgraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1055])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation.get_explanation_subgraph().prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1055])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation.get_explanation_subgraph().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroExplanation(\n",
       "  prediction=[1],\n",
       "  target=[1],\n",
       "  edge_label_index=[2],\n",
       "  \u001b[1mmovie\u001b[0m={\n",
       "    node_mask=[0, 404],\n",
       "    x=[0, 404]\n",
       "  },\n",
       "  \u001b[1muser\u001b[0m={\n",
       "    node_mask=[0, 610],\n",
       "    x=[0, 610]\n",
       "  },\n",
       "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
       "    edge_mask=[0],\n",
       "    edge_index=[2, 0]\n",
       "  },\n",
       "  \u001b[1m(movie, rev_rates, user)\u001b[0m={\n",
       "    edge_mask=[0],\n",
       "    edge_index=[2, 0]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation.get_complement_subgraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 386, 4493])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_label_index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GNN explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=10),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='edge',\n",
    "        return_type='raw',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Heterogeneous graphs not yet supported in 'GNNExplainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m explanation \u001b[39m=\u001b[39m explainer(\n\u001b[1;32m      2\u001b[0m     \u001b[39m# x={\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[39m#     \"movie\": train_data[\"movie\"],\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[39m#     \"user\": train_data[\"user\"]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[39m# },\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[39m# edge_index=train_data[(\"user\", \"rates\", \"movie\")].edge_index,\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \n\u001b[1;32m      8\u001b[0m     edge_index\u001b[39m=\u001b[39mtrain_data\u001b[39m.\u001b[39medge_index_dict,\n\u001b[1;32m      9\u001b[0m     \n\u001b[1;32m     10\u001b[0m     \u001b[39m# edge_index=train_data[(\"user\", \"rates\", \"movie\")].edge_index,\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \n\u001b[1;32m     12\u001b[0m     x\u001b[39m=\u001b[39mtrain_data\u001b[39m.\u001b[39mx_dict,\n\u001b[1;32m     13\u001b[0m     \n\u001b[1;32m     14\u001b[0m     \u001b[39m# edge_index_dict=train_data.edge_index_dict,\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \n\u001b[1;32m     16\u001b[0m     edge_label_index\u001b[39m=\u001b[39mtrain_data[\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmovie\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39medge_label_index,\n\u001b[1;32m     17\u001b[0m     \n\u001b[1;32m     18\u001b[0m     \u001b[39m# edge_index=train_data.edge_index_dict[('user', 'rates', 'movie')],\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[39m# edge_label_index=train_data,\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \n\u001b[1;32m     21\u001b[0m     target\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch_geometric/explain/explainer.py:198\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtraining\n\u001b[1;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[0;32m--> 198\u001b[0m explanation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malgorithm(\n\u001b[1;32m    199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    200\u001b[0m     x,\n\u001b[1;32m    201\u001b[0m     edge_index,\n\u001b[1;32m    202\u001b[0m     target\u001b[39m=\u001b[39;49mtarget,\n\u001b[1;32m    203\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    204\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    205\u001b[0m )\n\u001b[1;32m    207\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain(training)\n\u001b[1;32m    209\u001b[0m \u001b[39m# Add explainer objectives to the `Explanation` object:\u001b[39;00m\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch_geometric/explain/algorithm/gnn_explainer.py:71\u001b[0m, in \u001b[0;36mGNNExplainer.forward\u001b[0;34m(self, model, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m     61\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     62\u001b[0m     model: torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m     69\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Explanation:\n\u001b[1;32m     70\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(edge_index, \u001b[39mdict\u001b[39m):\n\u001b[0;32m---> 71\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHeterogeneous graphs not yet supported in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m                          \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m     hard_node_mask \u001b[39m=\u001b[39m hard_edge_mask \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_config\u001b[39m.\u001b[39mtask_level \u001b[39m==\u001b[39m ModelTaskLevel\u001b[39m.\u001b[39mnode:\n\u001b[1;32m     76\u001b[0m         \u001b[39m# We need to compute hard masks to properly clean up edges and\u001b[39;00m\n\u001b[1;32m     77\u001b[0m         \u001b[39m# nodes attributions not involved during message passing:\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Heterogeneous graphs not yet supported in 'GNNExplainer'"
     ]
    }
   ],
   "source": [
    "explanation = explainer(\n",
    "    # x={\n",
    "    #     \"movie\": train_data[\"movie\"],\n",
    "    #     \"user\": train_data[\"user\"]\n",
    "    # },\n",
    "    # edge_index=train_data[(\"user\", \"rates\", \"movie\")].edge_index,\n",
    "    \n",
    "    edge_index=train_data.edge_index_dict,\n",
    "    \n",
    "    # edge_index=train_data[(\"user\", \"rates\", \"movie\")].edge_index,\n",
    "    \n",
    "    x=train_data.x_dict,\n",
    "    \n",
    "    # edge_index_dict=train_data.edge_index_dict,\n",
    "    \n",
    "    edge_label_index=train_data['user', 'movie'].edge_label_index,\n",
    "    \n",
    "    # edge_index=train_data.edge_index_dict[('user', 'rates', 'movie')],\n",
    "    # edge_label_index=train_data,\n",
    "    \n",
    "    target=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HeteroExplanation' has no attribute 'visualize_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn [23], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m explanation\u001b[39m.\u001b[39mget_explanation_subgraph()\u001b[39m.\u001b[39mvisualize_graph()\n",
      "\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch_geometric/data/hetero_data.py:133\u001b[0m, in \u001b[0;36mHeteroData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[1;32m    131\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mbool\u001b[39m(re\u001b[39m.\u001b[39msearch(\u001b[39m'\u001b[39m\u001b[39m_dict$\u001b[39m\u001b[39m'\u001b[39m, key)):\n",
      "\u001b[1;32m    132\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollect(key[:\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m])\n",
      "\u001b[0;32m--> 133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has no \u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    134\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mattribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HeteroExplanation' has no attribute 'visualize_graph'"
     ]
    }
   ],
   "source": [
    "explanation.get_explanation_subgraph().visualize_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Captum explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=CaptumExplainer(attribution_method=\"IntegratedGradients\"),\n",
    "    explanation_type='model',\n",
    "    # node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='regression',\n",
    "        task_level='edge',\n",
    "        return_type='raw',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [131903] at index 0 does not match the shape of the indexed tensor [2, 131903] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m explanation \u001b[39m=\u001b[39m explainer(\n\u001b[1;32m      2\u001b[0m     \u001b[39m# x={\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[39m#     \"movie\": train_data[\"movie\"],\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[39m#     \"user\": train_data[\"user\"]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[39m# },\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[39m# edge_index=train_data[(\"user\", \"rates\", \"movie\")].edge_index,\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \n\u001b[1;32m      8\u001b[0m     edge_index\u001b[39m=\u001b[39mtrain_data\u001b[39m.\u001b[39medge_index_dict,\n\u001b[1;32m      9\u001b[0m     \n\u001b[1;32m     10\u001b[0m     \u001b[39m# edge_index=train_data[(\"user\", \"rates\", \"movie\")].edge_index,\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \n\u001b[1;32m     12\u001b[0m     x\u001b[39m=\u001b[39mtrain_data\u001b[39m.\u001b[39mx_dict,\n\u001b[1;32m     13\u001b[0m     \n\u001b[1;32m     14\u001b[0m     \u001b[39m# edge_index_dict=train_data.edge_index_dict,\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \n\u001b[1;32m     16\u001b[0m     edge_label_index\u001b[39m=\u001b[39mtrain_data[\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmovie\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39medge_label_index,\n\u001b[1;32m     17\u001b[0m     \n\u001b[1;32m     18\u001b[0m     \u001b[39m# edge_index=train_data.edge_index_dict[('user', 'rates', 'movie')],\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[39m# edge_label_index=train_data,\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \n\u001b[1;32m     21\u001b[0m     target\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch_geometric/explain/explainer.py:192\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[39mif\u001b[39;00m target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    190\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m\u001b[39m should not be provided for the explanation \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplanation_type\u001b[39m.\u001b[39mvalue\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 192\u001b[0m     prediction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_prediction(x, edge_index, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    193\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_target(prediction)\n\u001b[1;32m    195\u001b[0m training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtraining\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch_geometric/explain/explainer.py:115\u001b[0m, in \u001b[0;36mExplainer.get_prediction\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[1;32m    114\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 115\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain(training)\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [7], line 188\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x_dict, edge_index_dict, edge_label_index)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x_dict, edge_index_dict, edge_label_index):\n\u001b[0;32m--> 188\u001b[0m     z_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x_dict, edge_index_dict)\n\u001b[1;32m    189\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(z_dict, edge_label_index)\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch/fx/graph_module.py:652\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_wrapped\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrapped_call(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch/fx/graph_module.py:277\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch/fx/graph_module.py:267\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcls_call(obj, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    266\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcls, obj)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    269\u001b[0m     \u001b[39massert\u001b[39;00m e\u001b[39m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m<eval_with_key>.1:11\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m      9\u001b[0m edge_index__user__rates__movie \u001b[39m=\u001b[39m edge_index_dict\u001b[39m.\u001b[39mget((\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrates\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmovie\u001b[39m\u001b[39m'\u001b[39m), \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m edge_index__movie__rev_rates__user \u001b[39m=\u001b[39m edge_index_dict\u001b[39m.\u001b[39mget((\u001b[39m'\u001b[39m\u001b[39mmovie\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrev_rates\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m), \u001b[39mNone\u001b[39;00m);  edge_index_dict \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m convs_0__movie \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvs, \u001b[39m\"\u001b[39;49m\u001b[39m0\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49muser__rates__movie((x__user, x__movie), edge_index__user__rates__movie)\n\u001b[1;32m     12\u001b[0m convs_0__user \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs, \u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmovie__rev_rates__user((x__movie, x__user), edge_index__movie__rev_rates__user);  x__movie \u001b[39m=\u001b[39m x__user \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     13\u001b[0m relu__movie \u001b[39m=\u001b[39m convs_0__movie\u001b[39m.\u001b[39mrelu();  convs_0__movie \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch_geometric/nn/conv/sage_conv.py:131\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    128\u001b[0m     x \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(x[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mrelu(), x[\u001b[39m1\u001b[39m])\n\u001b[1;32m    130\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, size\u001b[39m=\u001b[39;49msize)\n\u001b[1;32m    132\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_l(out)\n\u001b[1;32m    134\u001b[0m x_r \u001b[39m=\u001b[39m x[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:449\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplain:\n\u001b[1;32m    447\u001b[0m     explain_msg_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minspector\u001b[39m.\u001b[39mdistribute(\n\u001b[1;32m    448\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mexplain_message\u001b[39m\u001b[39m'\u001b[39m, coll_dict)\n\u001b[0;32m--> 449\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexplain_message(out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mexplain_msg_kwargs)\n\u001b[1;32m    451\u001b[0m aggr_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minspector\u001b[39m.\u001b[39mdistribute(\u001b[39m'\u001b[39m\u001b[39maggregate\u001b[39m\u001b[39m'\u001b[39m, coll_dict)\n\u001b[1;32m    452\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_forward_pre_hooks\u001b[39m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:559\u001b[0m, in \u001b[0;36mMessagePassing.explain_message\u001b[0;34m(self, inputs, size_i)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[39m# Some ops add self-loops to `edge_index`. We need to do the same for\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[39m# `edge_mask` (but do not train these entries).\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[39mif\u001b[39;00m inputs\u001b[39m.\u001b[39msize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_dim) \u001b[39m!=\u001b[39m edge_mask\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m):\n\u001b[0;32m--> 559\u001b[0m     edge_mask \u001b[39m=\u001b[39m edge_mask[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_loop_mask]\n\u001b[1;32m    560\u001b[0m     loop \u001b[39m=\u001b[39m edge_mask\u001b[39m.\u001b[39mnew_ones(size_i)\n\u001b[1;32m    561\u001b[0m     edge_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([edge_mask, loop], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [131903] at index 0 does not match the shape of the indexed tensor [2, 131903] at index 0"
     ]
    }
   ],
   "source": [
    "explanation = explainer(\n",
    "    # x={\n",
    "    #     \"movie\": train_data[\"movie\"],\n",
    "    #     \"user\": train_data[\"user\"]\n",
    "    # },\n",
    "    # edge_index=train_data[(\"user\", \"rates\", \"movie\")].edge_index,\n",
    "    \n",
    "    edge_index=train_data.edge_index_dict,\n",
    "    \n",
    "    # edge_index=train_data[(\"user\", \"rates\", \"movie\")].edge_index,\n",
    "    \n",
    "    x=train_data.x_dict,\n",
    "    \n",
    "    # edge_index_dict=train_data.edge_index_dict,\n",
    "    \n",
    "    edge_label_index=train_data['user', 'movie'].edge_label_index,\n",
    "    \n",
    "    # edge_index=train_data.edge_index_dict[('user', 'rates', 'movie')],\n",
    "    # edge_label_index=train_data,\n",
    "    \n",
    "    target=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroExplanation(\n",
       "  prediction=[131903],\n",
       "  target=[131903],\n",
       "  edge_label_index=[2, 131903],\n",
       "  \u001b[1mmovie\u001b[0m={\n",
       "    node_mask=[2055, 768],\n",
       "    x=[2055, 768]\n",
       "  },\n",
       "  \u001b[1muser\u001b[0m={\n",
       "    node_mask=[4633, 4633],\n",
       "    x=[4633, 4633]\n",
       "  },\n",
       "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
       "    edge_mask=[131903],\n",
       "    edge_index=[2, 131903]\n",
       "  },\n",
       "  \u001b[1m(movie, rev_rates, user)\u001b[0m={\n",
       "    edge_mask=[131903],\n",
       "    edge_index=[2, 131903]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation.get_explanation_subgraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acbc58aadc5672afc04cc91f2a1726d8eb7b999e15e50d024070fdc74729208f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
