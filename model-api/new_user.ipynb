{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import torch\n",
    "import torch_geometric\n",
    "import matplotlib.pyplot as plt\n",
    "parent_path = pathlib.Path(os.getcwd()).parent.absolute()\n",
    "sys.path.append(str(parent_path))\n",
    "from helpers.Neo4jMovieLensMetadata import Neo4jMovieLensMetaData\n",
    "from helpers.dataset import load_data_dataset\n",
    "from helpers.get_model import get_model, get_model_name\n",
    "from helpers.recommendations import make_predictions, recommend"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have just added a new user with user_id 673"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the dataset and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding title...\n",
      "Encoding original_title...\n",
      "Encoding fastRP_genres...\n",
      "Encoding fastRP_keywords...\n",
      "Encoding fastRP_cast...\n",
      "Encoding fastRP_crew...\n",
      "Encoding fastRP_production_companies...\n",
      "Encoding fastRP_production_countries...\n",
      "Encoding fastRP_spoken_languages...\n",
      "[torch.Size([9067, 384]), torch.Size([9067, 384]), torch.Size([9067, 256]), torch.Size([9067, 256]), torch.Size([9067, 256]), torch.Size([9067, 256]), torch.Size([9067, 256]), torch.Size([9067, 256]), torch.Size([9067, 256])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset, data = load_data_dataset(\"bolt://localhost:7687\", \"neo4j\", \"admin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (encoder): GraphModule(\n",
       "    (convs): Module(\n",
       "      (0): Module(\n",
       "        (user__rates__movie): SAGEConv(-1, 16, aggr=mean)\n",
       "        (movie__rev_rates__user): SAGEConv(-1, 16, aggr=mean)\n",
       "      )\n",
       "      (1): Module(\n",
       "        (user__rates__movie): SAGEConv(16, 16, aggr=mean)\n",
       "        (movie__rev_rates__user): SAGEConv(16, 16, aggr=mean)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): EdgeDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=32, out_features=16, bias=True)\n",
       "      (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (3): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (4): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (5): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (6): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (7): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (8): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (9): Linear(in_features=16, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_children(m: torch.nn.Module):\n",
    "    children = dict(m.named_children())\n",
    "    output = {}\n",
    "    if children == {}:\n",
    "        # if module has no children; m is last child! :O\n",
    "        return m\n",
    "    else:\n",
    "        # look for children from children... to the last child!\n",
    "        for name, child in children.items():\n",
    "            try:\n",
    "                output[name] = nested_children(child)\n",
    "            except TypeError:\n",
    "                output[name] = nested_children(child)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'convs': {'0': {'user__rates__movie': {'aggr_module': MeanAggregation(),\n",
       "    'lin_l': Linear(671, 16, bias=True),\n",
       "    'lin_r': Linear(2560, 16, bias=False)},\n",
       "   'movie__rev_rates__user': {'aggr_module': MeanAggregation(),\n",
       "    'lin_l': Linear(2560, 16, bias=True),\n",
       "    'lin_r': Linear(671, 16, bias=False)}},\n",
       "  '1': {'user__rates__movie': {'aggr_module': MeanAggregation(),\n",
       "    'lin_l': Linear(16, 16, bias=True),\n",
       "    'lin_r': Linear(16, 16, bias=False)},\n",
       "   'movie__rev_rates__user': {'aggr_module': MeanAggregation(),\n",
       "    'lin_l': Linear(16, 16, bias=True),\n",
       "    'lin_r': Linear(16, 16, bias=False)}}}}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_children(model.encoder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for the new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([675, 675])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x_dict[\"user\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100717])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index_dict[(\"user\", \"rates\", \"movie\")].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test for the current user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN GNN ENCODER\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (9067x675 and 674x16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [172], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[39m=\u001b[39m make_predictions(dataset, data, model, \u001b[39m673\u001b[39m)\n",
      "File \u001b[0;32m~/diploma/model-api/helpers/recommendations.py:46\u001b[0m, in \u001b[0;36mmake_predictions\u001b[0;34m(dataset, data, model, user_id, is_test)\u001b[0m\n\u001b[1;32m     42\u001b[0m     z_dict \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39mx_dict, data\u001b[39m.\u001b[39medge_index_dict,\n\u001b[1;32m     43\u001b[0m              edge_label_index, is_test\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m z_dict\n\u001b[0;32m---> 46\u001b[0m pred \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39;49mx_dict, data\u001b[39m.\u001b[39;49medge_index_dict,\n\u001b[1;32m     47\u001b[0m              edge_label_index)\n\u001b[1;32m     48\u001b[0m pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mclamp(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m     50\u001b[0m mask \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mnonzero(as_tuple\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/diploma/model-api/helpers/model.py:213\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x_dict, edge_index_dict, edge_label_index, is_test)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x_dict, edge_index_dict, edge_label_index, is_test\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    212\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIN GNN ENCODER\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 213\u001b[0m     z_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x_dict, edge_index_dict)\n\u001b[1;32m    214\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOUT OF GNN ENCODER\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    215\u001b[0m     \u001b[39mif\u001b[39;00m is_test:\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch/fx/graph_module.py:652\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_wrapped\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrapped_call(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch/fx/graph_module.py:277\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch/fx/graph_module.py:267\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcls_call(obj, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    266\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcls, obj)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    269\u001b[0m     \u001b[39massert\u001b[39;00m e\u001b[39m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m<eval_with_key>.6:9\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m      7\u001b[0m get_2 \u001b[39m=\u001b[39m edge_index\u001b[39m.\u001b[39mget((\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrates\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmovie\u001b[39m\u001b[39m'\u001b[39m), \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m get_3 \u001b[39m=\u001b[39m edge_index\u001b[39m.\u001b[39mget((\u001b[39m'\u001b[39m\u001b[39mmovie\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrev_rates\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m), \u001b[39mNone\u001b[39;00m);  edge_index \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m convs_0_user__rates__movie \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvs, \u001b[39m\"\u001b[39;49m\u001b[39m0\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49muser__rates__movie((get_1, get), get_2)\n\u001b[1;32m     10\u001b[0m convs_0_movie__rev_rates__user \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs, \u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmovie__rev_rates__user((get, get_1), get_3);  get \u001b[39m=\u001b[39m get_1 \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     11\u001b[0m relu \u001b[39m=\u001b[39m convs_0_user__rates__movie\u001b[39m.\u001b[39mrelu();  convs_0_user__rates__movie \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch_geometric/nn/conv/sage_conv.py:132\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[1;32m    131\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate(edge_index, x\u001b[39m=\u001b[39mx, size\u001b[39m=\u001b[39msize)\n\u001b[0;32m--> 132\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlin_l(out)\n\u001b[1;32m    134\u001b[0m x_r \u001b[39m=\u001b[39m x[\u001b[39m1\u001b[39m]\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_weight \u001b[39mand\u001b[39;00m x_r \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/diploma/environ/lib/python3.9/site-packages/torch_geometric/nn/dense/linear.py:129\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    125\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39m        x (Tensor): The features.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (9067x675 and 674x16)"
     ]
    }
   ],
   "source": [
    "predictions = make_predictions(dataset, data, model, 673)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's dive..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* new adjacency matrix is of shape [num_movies, num_users]\n",
    "* old weight matrix of the model is of shape [old_num_users, hidden_channels]\n",
    "* num_users != old_num_users\n",
    "\n",
    "so we will modify by hand the weight matrix of the model and add one new random row for the new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_children(m: torch.nn.Module):\n",
    "    children = dict(m.named_children())\n",
    "    output = {}\n",
    "    if children == {}:\n",
    "        # if module has no children; m is last child! :O\n",
    "        return m\n",
    "    else:\n",
    "        # look for children from children... to the last child!\n",
    "        for name, child in children.items():\n",
    "            try:\n",
    "                output[name] = nested_children(child)\n",
    "            except TypeError:\n",
    "                output[name] = nested_children(child)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'convs': {'0': {'user__rates__movie': {'aggr_module': MeanAggregation(),\n",
       "    'lin_l': Linear(671, 16, bias=True),\n",
       "    'lin_r': Linear(2560, 16, bias=False)},\n",
       "   'movie__rev_rates__user': {'aggr_module': MeanAggregation(),\n",
       "    'lin_l': Linear(2560, 16, bias=True),\n",
       "    'lin_r': Linear(671, 16, bias=False)}},\n",
       "  '1': {'user__rates__movie': {'aggr_module': MeanAggregation(),\n",
       "    'lin_l': Linear(16, 16, bias=True),\n",
       "    'lin_r': Linear(16, 16, bias=False)},\n",
       "   'movie__rev_rates__user': {'aggr_module': MeanAggregation(),\n",
       "    'lin_l': Linear(16, 16, bias=True),\n",
       "    'lin_r': Linear(16, 16, bias=False)}}}}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_children(model.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2560"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(671, 16, bias=True): 675 users up to date\n",
      "Linear(2560, 16, bias=False): not a layer that throws the errors\n",
      "Linear(2560, 16, bias=True): not a layer that throws the errors\n",
      "Linear(671, 16, bias=False): 675 users up to date\n"
     ]
    }
   ],
   "source": [
    "num_users = dataset.my_mappings[\"users_mapping\"].__len__()\n",
    "convs = [conv for conv in model.encoder.convs.children()]\n",
    "conv = convs[0]\n",
    "dimension_to_ignore = nested_children(model.encoder)[\"convs\"][\"0\"][\"user__rates__movie\"][\"lin_r\"].weight.shape[1]\n",
    "for gnn_layer in conv.children():\n",
    "    for layer in gnn_layer.children():\n",
    "        if isinstance(layer, torch_geometric.nn.dense.Linear):\n",
    "            print(layer, end=\": \")\n",
    "            weight_matrix_users = layer.weight.shape[1]\n",
    "            if (weight_matrix_users == dimension_to_ignore):\n",
    "                    print(\"not a layer that throws the errors\")\n",
    "                    continue\n",
    "            if (weight_matrix_users == num_users):\n",
    "                print(f\"{num_users} users up to date\")\n",
    "            else:\n",
    "                print(f\"should add {num_users - weight_matrix_users} users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updates the weight matrix of the linear layers of the model\n",
    "# to have a dimension of 674 instead of 671\n",
    "# this is because the model was trained on a dataset with 671 users\n",
    "# and the new dataset has 674 users\n",
    "\n",
    "def update_model(model):\n",
    "    num_users = dataset.my_mappings[\"users_mapping\"].__len__()\n",
    "    convs = [conv for conv in model.encoder.convs.children()]\n",
    "    conv = convs[0]\n",
    "\n",
    "    for gnn_layer in conv.children():\n",
    "        for layer in gnn_layer.children():\n",
    "            if isinstance(layer, torch_geometric.nn.dense.Linear):\n",
    "                print(layer, end=\": \")\n",
    "                \n",
    "                weight_matrix_users = layer.weight.shape[1]\n",
    "                if (weight_matrix_users == 2560):\n",
    "                    print(\"not a layer that throws the errors\")\n",
    "                    continue\n",
    "\n",
    "                if (weight_matrix_users == num_users):\n",
    "                    print(f\"{num_users} users up to date\")\n",
    "                else:\n",
    "                    new_cols_num = num_users - weight_matrix_users\n",
    "                    if new_cols_num > 0:\n",
    "                        # add new columns with zeros to the weight matrix\n",
    "                        new_cols = torch.zeros(\n",
    "                            layer.weight.shape[0], new_cols_num)\n",
    "                        layer.weight = torch.nn.Parameter(\n",
    "                            torch.cat((layer.weight, new_cols), dim=1))\n",
    "                        print(f\"should add {new_cols_num} users\")\n",
    "                    else:\n",
    "                        print(f\"should remove {-new_cols_num} users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(671, 16, bias=True): should add 1 users\n",
      "Linear(2560, 16, bias=False): not a layer that throws the errors\n",
      "Linear(2560, 16, bias=True): not a layer that throws the errors\n",
      "Linear(671, 16, bias=False): should add 1 users\n"
     ]
    }
   ],
   "source": [
    "update_model(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN GNN ENCODER\n",
      "OUT OF GNN ENCODER\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 5.0)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = make_predictions(dataset, data, model, 674)\n",
    "vals = [pred[\"rating\"] for pred in predictions[\"predictedRatings\"]]\n",
    "plt.hist(vals)\n",
    "# set the range of the x-axis\n",
    "plt.xlim(0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pickled_model_small'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = get_model_name()\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "acbc58aadc5672afc04cc91f2a1726d8eb7b999e15e50d024070fdc74729208f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
